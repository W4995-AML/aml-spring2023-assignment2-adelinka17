{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2: Trees and Calibration\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Please push the .ipynb, .py, and .pdf to Github Classroom prior to the deadline. Please include your UNI as well.\n",
        "\n",
        "**Make sure to use the dataset that we provide in CourseWorks/Classroom.**\n",
        "\n",
        "**There are a lot of applied questions based on the code results. Please make sure to answer them all. These are primarily to test your understanding of the results your code generate (similar to any Data Science/ML case study interviews).**\n"
      ],
      "metadata": {
        "id": "PGK51ENiWK8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Name: \n",
        "\n",
        "## UNI: "
      ],
      "metadata": {
        "id": "IMh1gfa1WQ-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Dataset\n",
        "\n",
        "\n",
        "### Description\n",
        "\n",
        "This data set contains details of ecommerce product shipment tracking and the target variable is a binary variable reflecting the fact whether the product reached on time or not."
      ],
      "metadata": {
        "id": "h-WA9tIaWVo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time"
      ],
      "metadata": {
        "id": "ohzV1r4eWW7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Decision Trees"
      ],
      "metadata": {
        "id": "x9xC14h3WcKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1: Load the provided dataset**"
      ],
      "metadata": {
        "id": "3tGQU8PdWgIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "KUpVHIJVZ93o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2: Are there any missing values in the dataset?**"
      ],
      "metadata": {
        "id": "7b1FzZArWqp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "aA2iOzZmaKoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3: Plot side-by-side bars of class distribtuion for each category for the categorical feature and the target categories.**\n"
      ],
      "metadata": {
        "id": "YTiDRE_QWwrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "lVQAdWahaNBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4: Explain the distribution of the target variable and the dataset.**\n"
      ],
      "metadata": {
        "id": "6noNR9-bONiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "3EoP78rNaRk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5: Split the data into development and test datasets. Which splitting methodology did you choose and why?**\n",
        "\n",
        "**Hint: Based on the distribution of the data, try to use the best splitting strategy.**"
      ],
      "metadata": {
        "id": "ydfNqM4KW5AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "8TFVV3E3aTJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.6: Would you drop any column? Justify your reasoning.** \n",
        "\n",
        "**Preprocess the data (Handle the Categorical Variable). Do we need to apply scaling? Briefly Justify**\n",
        "\n"
      ],
      "metadata": {
        "id": "rl4Lkx0OXH3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "zT7iqLWCaXRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.7: Fit a Decision Tree on the development data until all leaves are pure. What is the performance of the tree on the development set and test set? Evaluate test and train accuarcy on F-1 score and accuracy.**"
      ],
      "metadata": {
        "id": "_LVpZEKDXPW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "75oSbcPgaY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.8: Visualize the trained tree until the max_depth 8.**"
      ],
      "metadata": {
        "id": "SwHLxOWVXVIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "d-9KvB-Laad3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.9: Prune the tree using one of the techniques discussed in class and evaluate the performance.**\n",
        "\n",
        "**Print the optimal value of the tuned parameter.**"
      ],
      "metadata": {
        "id": "XcupbfqxXbPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "6AkmNEgMab26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.10: List the top 3 most important features for this trained tree? How would you justify these features being the most important?**"
      ],
      "metadata": {
        "id": "Xevu4k1dXrld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "q3yp6g0laehf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Random Forests"
      ],
      "metadata": {
        "id": "0EaPUeMN5K62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1: Train a Random Forest model on the development dataset using RandomForestClassifier class in sklearn. Use the default parameters. Evaluate the performance of the model on test dataset. Use accuracy and F1 score to evaluate. Does this perform better than Decision Tree on the test dataset (compare to results in Q 1.7)?**"
      ],
      "metadata": {
        "id": "e4nmOojt5cAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "KTB50d0fagfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2: Do all trees in the trained random forest model have pure leaves? How would you verify that all trees have pure leaves? Print the score (mean accuracy) values of your choosen method**"
      ],
      "metadata": {
        "id": "QoJQilC78kv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "JqE9bxz6ah04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3: Assume you want to improve the performance of this model. Also, assume that you had to pick two hyperparameters that you could tune to improve its performance. Which hyperparameters would you choose and why?**\n"
      ],
      "metadata": {
        "id": "Nf_5wY4C8xHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION HERE"
      ],
      "metadata": {
        "id": "pGdmmTjSat6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4: Now, assume you had to choose up to 5 different values (each) for these two hyperparameters. How would you choose these values that could potentially give you a performance lift?**"
      ],
      "metadata": {
        "id": "4L5ymzKB84BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION HERE"
      ],
      "metadata": {
        "id": "y5N_oxH7av-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.5: Perform model selection using the chosen values for the hyperparameters. Use out-of-bag (OOB) error for finding the optimal hyperparameters. Report on the optimal hyperparameters. Estimate the performance of the optimal model (model trained with optimal hyperparameters) on train and test dataset? Has the performance improved over your plain-vanilla random forest model trained in Q2.1?**"
      ],
      "metadata": {
        "id": "ipLNT1y_84rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "1uRgvlVuayc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **2.6: Can you find the top 3 most important features from the model trained in Q2.5? How do these features compare to the important features that you found from Q1.10? If they differ, which feature set makes more sense?**"
      ],
      "metadata": {
        "id": "E99HR_mZA_cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "j-9fIM-ba0Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Gradient Boosted Trees"
      ],
      "metadata": {
        "id": "IwgYEfrfLh1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1: Choose three hyperparameters to tune HistGradientBoostingClassifier on the development dataset using 5-fold cross validation. For each hyperparmeter, give it 3 potential values. Report on the time taken to do model selection for the model. Also, report the performance of the test dataset from the optimal models.**"
      ],
      "metadata": {
        "id": "G22EKzRjLh1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Myo5M6am1Ljt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2: Repeat 3.1 for XGBoost.**\n",
        "\n",
        "**Note**: For XGBoost, you **DO NOT NEED** to choose the same hyperparameters as HistGradientBoostingClassifier."
      ],
      "metadata": {
        "id": "n1_47XwsLh1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "G-vzE9uh1MiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3: Compare the results on the test dataset of XGBoost and HistGradientBoostingClassifier. Which model do you prefer and why?**"
      ],
      "metadata": {
        "id": "LDcp7suzLh1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ZU3T-Mbc1NF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4: Can you list the top 3 important features from the trained XGBoost model? How do they differ from the features found from Random Forest and Decision Tree?**"
      ],
      "metadata": {
        "id": "MiLxyTs3Lh1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "uRg9zHXF1Nvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.5: Can you choose the top 5 features (as given by feature importances from XGBoost) and repeat Q3.2? Does this model perform better than the one trained in Q3.2? Why or why not is the performance better?**"
      ],
      "metadata": {
        "id": "XslKOV0zLh1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "tCOXabbZ1OY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4: Calibration"
      ],
      "metadata": {
        "id": "Z6X1i5-OH1dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1: Estimate the brier score for the HistGradientBoosting model (trained with optimal hyperparameters from Q3.2) scored on the test dataset.**"
      ],
      "metadata": {
        "id": "dzrqP5IEH4r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "99WKDH2M1PH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2: Calibrate the trained HistGradientBoosting model using Platt Scaling. Print the brier score after calibration and plot predicted v.s. actual on test datasets from the calibration method.**"
      ],
      "metadata": {
        "id": "FrwJNloIBlW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Lar6XNTk1Pw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3: Compare the brier scores from 4.1 and 4.2. Do the calibration methods help in having better predicted probabilities?**"
      ],
      "metadata": {
        "id": "IfBTkjtoIKfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE"
      ],
      "metadata": {
        "id": "4l-KRYw91QfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}